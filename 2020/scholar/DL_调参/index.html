<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>深度学习的操作们 | 嘲哳</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.1/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.1/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/2.0.4/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/2.1.4/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/2.1.4/toastr.min.css"><meta name="generator" content="Hexo 4.2.1"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">深度学习的操作们</h1><a id="logo" href="/.">嘲哳</a><p class="description">Joseph's Blog | PPLRDLL.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/tag/"><i class="fa fa-tag"> Tag</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/bookmark/"><i class="fa fa-bookmark"> Bookmark</i></a><a href="/timeline/"><i class="fa fa-hourglass"> Timeline</i></a><a href="/About/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">深度学习的操作们</h1><div class="post-meta">2020-06-27<span> | </span><span class="category"><a href="/categories/%E5%AD%A6%E6%9C%AF/">学术</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><span class="count"></span><span class="post-count"> 1.5k</span><span class="post-meta-item-text"> Words</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><span class="time"></span><span class="post-count"> 5</span><span class="post-meta-item-text"> Minutes</span></span></span></div><a class="disqus-comment-count" href="/2020/scholar/DL_%E8%B0%83%E5%8F%82/#vcomment"><span class="valine-comment-count" data-xid="/2020/scholar/DL_%E8%B0%83%E5%8F%82/"></span><span> Comment</span></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#有效措施"><span class="toc-text">有效措施</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据预处理"><span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#数据增广"><span class="toc-text">数据增广</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#数据标准化-归一化"><span class="toc-text">数据标准化&#x2F;归一化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#训练"><span class="toc-text">训练</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#损失函数权重"><span class="toc-text">损失函数权重</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#学习率衰减"><span class="toc-text">学习率衰减</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#不稳定措施"><span class="toc-text">不稳定措施</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#添加模型的全连接层"><span class="toc-text">添加模型的全连接层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dropout"><span class="toc-text">Dropout</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-task"><span class="toc-text">Multi-task</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#加载预训数据"><span class="toc-text">加载预训数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#基本无效措施"><span class="toc-text">基本无效措施</span></a></li></ol></div></div><br><br><br><div class="post-content"><p>每一次深度模型调参都是让人头疼的东西，总感觉有很多玄学的东西能用，但事实上最后效果都不会太好。这里专门记录一些可能会有影响的调参方法。所以这是一个累积更新的文章。希望之后碰到新的方法和雷区能在这里记下，减少调试时间。</p>
<a id="more"></a>  
<h2 id="有效措施"><a href="#有效措施" class="headerlink" title="有效措施"></a>有效措施</h2><h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>数据预处理的效果可能比模型的各种调参来得更加直接有效。对于 NLP 任务可能不那么明显，但是对于 CV 或者 DSP 任务却是立竿见影的。</p>
<h4 id="数据增广"><a href="#数据增广" class="headerlink" title="数据增广"></a>数据增广</h4><p>计算机视觉中常用的方法。基本是对于图片随机翻转、随机截取、添加高斯模糊、随机遮盖等等措施。其中随机截取和随机翻转是一般都有效的，随机遮盖等则不一定。数据增广可以在模型训练中完成，让模型实时更改数据集内容；也可以在训练前就完成增广；两种方法都用也没有问题。</p>
<p>对于图片的数据增广方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> tfs</span><br><span class="line">transform = tfs.Compose([</span><br><span class="line">    tfs.Resize((<span class="number">256</span>, <span class="number">256</span>)),  <span class="comment"># 先调整图片大小至256x256</span></span><br><span class="line">    tfs.RandomCrop((<span class="number">224</span>, <span class="number">224</span>)),  <span class="comment"># 再随机裁剪到224x224</span></span><br><span class="line">    tfs.RandomHorizontalFlip(),  <span class="comment"># 随机的图像水平翻转，通俗讲就是图像的左右对调</span></span><br><span class="line">    tfs.RandomRotation(<span class="number">5</span>),</span><br><span class="line">    tfs.ToTensor(),</span><br><span class="line">    tfs.Normalize((<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>), (<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.2225</span>)),  <span class="comment"># 维度和图像的channel相关</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>调用时使用即可：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = transform(img)</span><br></pre></td></tr></table></figure></p>
<h4 id="数据标准化-归一化"><a href="#数据标准化-归一化" class="headerlink" title="数据标准化/归一化"></a>数据标准化/归一化</h4><p>即使是非常简单的数据标准化/归一化，就能取得显著的 performance 提高以及训练速度的大幅度提升。对于图像信息，可以使用灰度图均衡化，而对于数字信号或者其他信息，则可以使用 MinMax，标准化众多方法。这个对于模型训练速度的提升可能是数量级上。</p>
<p>但无论如何，数据标准化几乎应当是数据预处理的必要操作，绝对不能跳过。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直方图均衡化</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">img = cv2.equalizeHist(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化 - 对于一维数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">std</span><span class="params">(data)</span>:</span></span><br><span class="line">    mu = np.mean(data)</span><br><span class="line">    sigma = np.std(data)</span><br><span class="line">    <span class="keyword">return</span> (data - mu) / sigma</span><br></pre></td></tr></table></figure>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><h4 id="损失函数权重"><a href="#损失函数权重" class="headerlink" title="损失函数权重"></a>损失函数权重</h4><p>对于普通的损失函数，对于不同的类加以相同的权进行处理。但是对于类分别不均的训练集/测试集，可以轻微调整模型的损失函数权重，一般权重添加方法是按照训练集的比例强行加权。一般这样就能获得略好的效果。但是还有一定的调整空间。事实上使用这个方法对于一些数据分布不均的方法有非常明显的效果。不过如果实在分布不均的话，可以考虑数据预处理方法解决。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weight = torch.Tensor([<span class="number">1</span>, <span class="number">0.8</span>])</span><br><span class="line">lossfun = nn.CrossEntropyLoss(weight = weight)</span><br></pre></td></tr></table></figure>
<p>如果使用 cuda 训练，还应该申明<code>.cuda()</code>。</p>
<h4 id="学习率衰减"><a href="#学习率衰减" class="headerlink" title="学习率衰减"></a>学习率衰减</h4><p>原来习惯性用 Adam 也就没有再关心过学习率的问题，但事实上学习率仍然是有影响的。使用过小的学习率前期的训练时间过长而且容易进入一个不太好的局部最优解，相反使用大的学习率在前期能够势如破竹。（甚至是数量级的提升）但是训练到后期的模型 performan 却需要更小的学习率，所以这里引入学习率衰减的方法。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">adjust_learning_rate</span><span class="params">(optimizer, epoch)</span>:</span></span><br><span class="line">    lr = <span class="number">1e-4</span> * (<span class="number">0.4</span> ** (epoch // <span class="number">8</span>))</span><br><span class="line">    <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">        param_group[<span class="string">'lr'</span>] = lr</span><br><span class="line">adjust_learning_rate(optimizer, epoch)</span><br></pre></td></tr></table></figure>
<p>传入的 optimizer 参数就是 PyTorch 的模型。对于 Adam 模型，建议使用 $1e^{-4}$ 作为起始训练速率。</p>
<h2 id="不稳定措施"><a href="#不稳定措施" class="headerlink" title="不稳定措施"></a>不稳定措施</h2><h3 id="添加模型的全连接层"><a href="#添加模型的全连接层" class="headerlink" title="添加模型的全连接层"></a>添加模型的全连接层</h3><p>添加全连接层会大幅度增加模型的复杂度以及参数量，强制减低模型的训练速度，但而提高模型的过拟合能力。所以增加全连接层方法在数据量不足以支撑的情况下是绝对不推荐的。但是有的时候能发挥一定的作用。</p>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>Dropout 不是万能的方法。例如对于最后的分类器叠加 Dropout 反而会使模型的表现变得滑稽。Dropout 的添加是需要通过反复实验的。不过建议在模型的一开始不要使用 Dropout，因为模型自身的能力可能就不够，不能够很好地拟合训练数据。而且增加 Dropout 增加了训练时间，对于判断模型的强度也是不利的。在实验的最后发现过拟合严重可以考虑尝试使用 Dropout 方法。</p>
<h3 id="Multi-task"><a href="#Multi-task" class="headerlink" title="Multi-task"></a>Multi-task</h3><p>这是一个很不确定的东西。Multi-task 的效果随着设计的多任务而变化。事实上，在我使用 Multi-task 的情况下，几乎都没有得到明显的提升，有的时候甚至会拖后腿使模型的能力下降。所以 Multi-task 是需要仔细思考后使用的。</p>
<h3 id="加载预训数据"><a href="#加载预训数据" class="headerlink" title="加载预训数据"></a>加载预训数据</h3><p>对于 NLP 任务，使用预训参数是必要的，特别是对于 BERT 等模型，即使固定参数，只训练后面的部分也能获得很好的效果。但是对于 CV 任务这个效果却不是一定的。例如在 COVID-19 分类任务中，我使用了 ResNet18 作为一个模型，并加载了 PyTorch 的预训结果，获得了训练速度的显著提升；然而在语谱图分类时，使用预训的结果并没有明显的优势。</p>
<p>所以模型的训练对象和预训的数据集应该有一定的共同之处时才能够发挥作用。语谱图是完全和 ImageNet 不同的东西，所以不能发挥作用也是在预期之中的。</p>
<h2 id="基本无效措施"><a href="#基本无效措施" class="headerlink" title="基本无效措施"></a>基本无效措施</h2></div><br><br><br><br><br><div class="tags"><a href="/tags/ML/"><i class="fa fa-tag"></i>ML</a></div><div class="post-nav"><a class="pre" href="/2020/scholar/DL_DCNN/">CV：深度卷积神经网络模型及调参</a><a class="next" href="/2020/tech/PyTorch_DataSet/">PyTorch方法：DataSet</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'true' == 'true' ? true : false;
var verify = 'false' == 'true' ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'OUsbWlgeyMM30tsscwdtIca5-MdYXbMMI',
  appKey:'UurECxSjfEQdvYhggt8KXW3w',
  placeholder:'Anything',
  avatar:'retro',
  guest_info:guest_info,
  pageSize:'10',
  lang:'en'
})
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Draft/">Draft</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AD%A6%E6%9C%AF/">学术</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E5%B7%A7/">技巧</a><span class="category-list-count">33</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9A%8F%E7%AC%94/">随笔</a><span class="category-list-count">66</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/CV/" style="font-size: 15px;">CV</a> <a href="/tags/ML/" style="font-size: 15px;">ML</a> <a href="/tags/PyTorch/" style="font-size: 15px;">PyTorch</a> <a href="/tags/%E6%80%AA%E4%BA%8B%E8%AE%B0/" style="font-size: 15px;">怪事记</a> <a href="/tags/NLP/" style="font-size: 15px;">NLP</a> <a href="/tags/C/" style="font-size: 15px;">C++</a> <a href="/tags/App/" style="font-size: 15px;">App</a> <a href="/tags/%E5%AE%89%E5%88%A9/" style="font-size: 15px;">安利</a> <a href="/tags/Go/" style="font-size: 15px;">Go</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Windows/" style="font-size: 15px;">Windows</a> <a href="/tags/Others/" style="font-size: 15px;">Others</a> <a href="/tags/%E8%84%9A%E6%9C%AC%E5%B7%A5%E5%85%B7/" style="font-size: 15px;">脚本工具</a> <a href="/tags/Paper/" style="font-size: 15px;">Paper</a> <a href="/tags/%E4%B9%A6%E4%BF%A1/" style="font-size: 15px;">书信</a> <a href="/tags/%E6%89%8B%E8%AE%B0/" style="font-size: 15px;">手记</a> <a href="/tags/%E6%9D%82%E8%AE%B0/" style="font-size: 15px;">杂记</a> <a href="/tags/%E8%A1%8C%E8%BF%B9/" style="font-size: 15px;">行迹</a> <a href="/tags/%E7%89%A9%E5%BF%97%E9%93%AD/" style="font-size: 15px;">物志铭</a> <a href="/tags/%E9%A3%9F%E8%B0%B1/" style="font-size: 15px;">食谱</a> <a href="/tags/%E8%A7%82%E6%84%9F/" style="font-size: 15px;">观感</a> <a href="/tags/Music/" style="font-size: 15px;">Music</a> <a href="/tags/%E9%9F%B3%E4%B9%90/" style="font-size: 15px;">音乐</a> <a href="/tags/%E8%AF%97%E6%AD%8C%EF%BC%9F/" style="font-size: 15px;">诗歌？</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/LaTeX/" style="font-size: 15px;">LaTeX</a> <a href="/tags/vscode/" style="font-size: 15px;">vscode</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/" style="font-size: 15px;">体系结构</a> <a href="/tags/DSP/" style="font-size: 15px;">DSP</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/essay/%E6%9D%82%E8%AE%B0/%E6%9C%88%E8%90%BD%E6%97%A5%E5%8D%87/">月落日升</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/tech/Obsidian/Obsidian%E6%8F%92%E4%BB%B6%E4%BD%BF%E7%94%A8/">Obsidian插件使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/tech/Obsidian/obsidian%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/">Obsidian使用指南</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/essay/%E6%89%8B%E8%AE%B0/%E7%83%9F%E8%8A%B1/">烟花</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/essay/%E6%89%8B%E8%AE%B0/%E5%A4%9C%E6%B8%B8%E8%AE%B0/">夜游记</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/essay/%E9%A3%9F%E5%A0%82%E4%BA%8C%E6%A5%BC/">食堂二楼</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/essay/%E8%AF%97%E6%AD%8C/%E6%88%91%E5%BC%80%E5%A7%8B%E6%98%8E%E7%99%BD%E6%88%91%E8%87%AA%E5%B7%B1%EF%BC%8C%E6%88%91%E4%B8%8D%E5%AD%98%E5%9C%A8/">我开始明白我自己，我不存在</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/essay/%E6%9D%82%E8%AE%B0/Ha(r)sh%20dreams/">Ha(r)sh dreams</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/essay/%E6%9D%82%E8%AE%B0/%E5%90%83%E8%91%A1%E8%90%84%E4%B8%8D%E5%90%90%E8%91%A1%E8%90%84%E7%9A%AE/">吃葡萄不吐葡萄皮</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/essay/%E6%9D%82%E8%AE%B0/%E6%98%A5%E6%B1%9F%E8%8A%B1%E6%9C%9D%E7%A7%8B%E6%9C%88%E5%A4%9C/">春江花朝秋月夜</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/tech/Loqseq%20%E8%83%A1%E4%B9%B1%E4%BD%BF%E7%94%A8/">Loqseq 胡乱使用手册</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/essay/%E7%89%A9%E5%BF%97/Joseph's%20Surface%20Book%202/">Joseph's Surface Book 2</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/essay/%E6%9D%82%E8%AE%B0/%E8%B7%AF%E8%BE%B9%E9%A3%8E%E5%B0%98%E6%95%85%E4%BA%8B%EF%BC%88%E5%85%B6%E4%B8%89%EF%BC%89/">路边风尘故事（其三）</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/Josep-h" title="GitHub" target="_blank">GitHub</a><ul></ul><a href="https://music.163.com/#/user/home?id=252635253" title="Music" target="_blank">Music</a><ul></ul><a href="https://space.bilibili.com/136778607/" title="Bilibili" target="_blank">Bilibili</a><ul></ul><a href="runpeng.xie@outlook.com" title="Mail" target="_blank">Mail</a><ul></ul><a href="https://blog.joseph-hails.site/atom.xml" title="RSS" target="_blank">RSS</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a href="/." rel="nofollow">嘲哳.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=0.0.0"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script><!-- add calendar widget --></div></body></html>